\documentclass{mprop}
\usepackage{graphicx}

% alternative font if you prefer \usepackage{times}

% for alternative page numbering use the following package and see documentation
% for commands \usepackage{fancyheadings}


% other potentially useful packages \uspackage{amssymb,amsmath}
\usepackage{url}
%\usepackage{fancyvrb} \usepackage[final]{pdfpages}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Is Technical Debt Real?}
\author{Ovidiu Popoviciu}
\date{18th December 2017}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents 
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{intro}

The phenomenon of technical debt has matured in recent years with numerous
scientific experiments conducted for its identification, measurement and
management. Initially coined in 1993 \cite{Cunningham1993}, it defined the
concept of not quite right code that provided gains in the short term. Thus
technical debt might be useful in achieving immediate deadlines with possible
software quality sacrifices that might be negative for future work. Negative
consequences in the long term could see software complexity growth, the
prevalence of bugs and defects, decreased team productivity and augmented work
effort, leading to increased costs of development, infrastructure and
management. The phenomenon affects daily work of developers, project managers
and stakeholders of the business. 

The definition of technical debt has been updated since then, spanning not just
activities related to code implementation but the entire software development
environment. The scientific community identified multiple types of debts
\cite{Li2015}, each with its advantages and consequences if not handled
accordingly. Although industry practitioners are aware of its presence
\cite{Codabux2013} \cite{Lim2012}, there is no standard way of measuring the
current and future impact of technical debt on development and costs of the
team. Additionally, due to lack of vocabulary and complexities of the
phenomenon, developers find it difficult to convey their concerns to project
stakeholders \cite{Kruchten2012}.

The primary research objective is to analyse work effort of feature
implementations within software projects with the purpose of identifying extra
work in the context of technical debt. An additional objective is to understand
how the measure of technical debt varies with software evolution and what types
of features incur or reduce its presence. The research questions have been
organised using the Goal-Question-Metric approach \cite{VanSolingen2002}:
\begin{itemize}
	\item \textbf{RQ1}. Can technical debt be measured in the context of work
	effort?
	      \begin{itemize}
		      \item \textbf{RQ1.1}: What was the difference (delta) in the
		            estimated work effort for a feature and the practical work
		            effort?
			  \item \textbf{RQ1.2}: What was the level of technical debt across
		            feature changesets at the time of implementation?
		      \item \textbf{RQ1.3}: How does the work effort delta vary with the
		            magnitude of technical debt?
		  \end{itemize}
	\item \textbf{RQ2}: What are the development patterns surrounding feature
	      lifecycle?
	      \begin{itemize}
		      \item \textbf{RQ2.1}: At what checkpoints in feature development
		            is technical debt reduction (refactoring) most prominent?
		      \item \textbf{RQ2.2}: What type of work items incur the most
					technical debt?
	      \end{itemize}
\end{itemize}

The main questions RQ1 and RQ2 will be tackled by answering their following
subquestions. The following metrics will be computed and analysed:
\begin{itemize}
	\item The \textbf{practical work effort} spent on feature implementation
	will be calculated by leveraging data from the team's issue tracker and
	version control repository.
	\item The level of \textbf{technical debt} in the system at the time of
	implementation will be measured in terms of code smells and bad coding
	practices.
	\item The \textbf{extra effort} spent on feature implementation will be
	derived as the difference between the estimated and practical effort
	measurements. 
\end{itemize}

The study will use both open-source and commercial projects in order understand
the contrast between the two worlds in the context of technical debt work
effort. We will select data candidates according to various criteria items such
as development model, version control system, availability of initially
estimated work effort data and suitability of code quality tools.

If successful, the study will increase awareness of technical debt in all areas
of the software development environment. Developers will know which code smells
and bad practices have the most impact on their productivity. Project managers
will recognise the costs of debt items within the system and assign appropriate
refactoring activities for each development iteration. Stakeholders will grasp
the impact of incurring technical debt and the effects on the costs of present
and future development of new features. Additionally, the study will highlight
refactoring development patterns of feature development lifecycle. To the best
of my knowledge, this is the first study to highlight technical debt interest
from the perspective of work effort and drill down into the development patterns
of technical debt accrual by increasing the granularity of data.

The proposal is structured as follows. Section \ref{lit-review} highlights
related work on technical debt by covering definition, types, identification,
measurement and management within software teams. Section \ref{proposed-work}
underlines future steps of the study and the deadlines and deliverables are
defined in Section \ref{work-plan}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background Survey}
\label{lit-review}

\subsection{Study Design}

Technical debt has become a broad topic in the scientific community over the
past few years. Many studies highlight the identification, measurement and
management of debt, each applied on a specific or multiple domains, each with
its advantages and disadvantages, each with many contributions and limitations.

To conduct a thorough literature survey, the following topics have been explored:
\begin{itemize}
	\item Definitions of technical debt.
	\item Types of debt.
	\item Identification.
	\item Measurement of principal and interest.
	\item Code quality tools.
	\item Management of debt.
	\item Industry case studies.
\end{itemize}

First of all, the definition of technical debt was explored with ways in which
the scientific community understood the metaphor, where it broke down, its
applications and consequences. Since \emph{debt} comes from a financial
terminology, it was ideal to understand the metaphor in more detail.

Second of all, it was important to understand the types of technical debt
discussed in the community, along with industry case studies. Practitioners
provide valuable information as they deal with technical debt and its costs
daily, whether they are developers, architects, managers or business
stakeholders.

Third of all, identification of technical debt and code quality tools were
important as they provide a way to highlight code violations in the system's
source code. This was important since this study will make use of code quality
tools in order to highlight potential code smells and assess their impact.

Fourth of all, measurement and calculation of technical debt was an important
topic, since it is difficult to aggregate such a complex phenomenon into a
single value.

Lastly, of extreme value to proprietary projects is the management of technical
debt. This topic included finding studies on managing debt within Agile
methodologies and practices that help guard against it.

The main source of information was the Workshop of Managing Technical Debt, with
many papers of its yearly workshop included in this study. The data sources were
ACM Digital Library and IEEE Xplore Digital Library, with search terms being
executed from Google Scholar. Additional techniques for finding new papers
included the snowballing technique which pointed to relevant studies in the
domain of software refactoring.

Although the study includes approximately 40 papers, it does not include all
papers related to technical debt. The literature search was mainly focused on
code and design debt, as well as tools and management practices in order to
combat these two types of debt.

\subsection{Definition, Perspectives and Types}
\label{section:def}

% Ward Cunningham - WyCash Portfolio Management System TODO: expand the
% definition from the paper.
Technical debt is a metaphor termed by Cunningham, in his note on the WyCash
Portfolio Management System \cite{Cunningham1993}. In the report, Cunningham
mentioned that \textit{shipping first time code is like going into debt} and
that as the system evolves new features would become more and more difficult to
implement. This phenomenon was due to feature-rich projects being shipped to
customers early but poorly written with little or no consideration to quality
and to future work.

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{visualisations/TD_trend.png}
	\caption{Technical Debt Trend from 2004 to Present}
	\label{fig:td-trend}
\end{figure}

% MTD 2010
The metaphor was ignored for a long time, until the late 2000s, when more and
more studies started to explore the phenomenon and possible management
processes. A figure of the popularity of Technical Debt from 2004 to present can
be seen in Figure \ref{fig:td-trend}, information provided by Google Trends
\cite{GoogleTrends}. The \textit{y} axis represents the interest in technical
debt over time (\textit{x} axis). A value of 100 represents peak search interest
popularity.

Thus, the first workshop on managing technical debt took place in 2010, where an
initial research agenda was proposed for the future of software engineering
field. Since then, workshops have been held every year, which consisted
seminars, presentations and brainstorming sessions on aspects such as definition
\cite{Kruchten2012} \cite{Theodoropoulos2011} \cite{Schmid2013}, identification
\cite{Ernst2012}, measurement \cite{Letouzey2012} \cite{Curtis2012}
\cite{Nugroho2011} \cite{Zazworka2011} \cite{Fontana2012} \cite{Bohnet2011},
management \cite{Guo2011} \cite{Zazworka2011Prioritise} \cite{Seaman2012} to
industry case studies \cite{Lim2012} \cite{Morgenthaler2012} \cite{Codabux2013}
\cite{Holvitie2014} \cite{Klinger2011}.

% from metaphor to theory and practice TODO: add citation to industry case
% studies
The definition of technical debt relies heavily on the perspective of the viewer
and her responsibility within the software development environment. Developers view
technical debt as a list of software quality issues and correlate it with lack
of time to implement features "\textit{properly}" \cite{Codabux2013}. Product
managers and stakeholders view at it as a strategy, a way to defer quality work
for fast work in order to satisfy certain business requirements, such as Time to
Market (TTM). In practice, these two perspectives are widely different, with
developers prioritising "invisible" code perfection whilst management focusing
on rapid development of "visible", selling point features. Kurchten et al.
\cite{Kruchten2012} defined technical debt as technological gaps between
development teams and management, where a gap is the evolution of a context
specific to a decision taken in the past. These gaps might have been decisions
that seemed correct when the decision was taken however, with the passing of
time, the initial decision incurred debt within the project. For example, there
is no tool that predicts what frameworks and languages will exist in the future
or how to implement features by considering future unknown requirements. As a
consequence, the authors state that technical debt is not the collection of code
quality violations within the results of static code analyzers but, a phenomenon
which is heavily reliant on present and future project evolution.


% from a stakeholder's perspective
However, most strategic decisions on the future evolution of the project come
from management. Unfortunately, stakeholders might not have knowledge of the
metaphor of technical debt, its current measurement and whether it impacts costs
of development. Their main focus of increasing business value through the
addition of visual features, rather than looking for investment in the quality
of the software being produced. As a result, new features are prioritised and
pressured on being delivered as early and as quickly as possible. These types of
issues affect the \textbf{extrinsic quality} of software and are "visible". For
example, an extrinsic quality characteristic is usability. Deferring user
experience work and ignoring user interface bugs might force users of the system
to find "ways around" certain tasks. The result is negative impact in user
productivity and the general usefulness of the product. Extrinsic
characteristics are important to the business as they are considered "sell
points" of the product. On the other hand, \textbf{intrinsic quality}
characteristics of software are the low-level issues such as code smells,
best-practices violations that might slow down development of new features
unless refactoring processes are applied. Theodoropoulos et al.
\cite{Theodoropoulos2011} considered that intrinsic and extrinsic software
quality characteristics are interdependent and deferring quality maitainence in
one area may affect other areas of quality. For example, improper data
validation in the business logic layer of the system, may impact downstream
components, such as user interface, and produce bugs within the system.


% on the limits of td metaphor TODO: define principal and interest
Although the use of finance terms may simplify technical characteristics of
software quality in the dialogue between development teams and stakeholders, the
analogy breaks down as studied by Schimd et al. \cite{Schmid2013}. In their
study, the authors had identified shortcomings in the financial metaphor
established by Ward Cunningham \cite{Cunningham1993} and found points where it
breaks down. In the financial domain, debt is a well known arrangement between
two parties where one party borrowes a fixed amount of money from the other
party \cite{debt-investopedia}. The most well known types of debt are loans,
where the terms of the arrangement dictate that the amount of money borrowed
must be paid back in full after a fixed period of time, along with fixed
interest payments paid annually.

Schmid et al. \cite{Schmid2013} has identified three major points where the
analogy breaks down:
\begin{itemize}
	\item \textit{Unit of measurement}. In finance there is a clear unit of
	      monetary measurement through the use of international currencies. In
	      contrast, technical debt does not have a standard unit of measurement
	      defined. There are many tools (TODO: add citation of paper tools here)
	      that provide a single, quantified and aggregated measure of the amount
	      of time it takes for software quality issues to be resolved.
	      Additionally, very few of these tools quantify the consequences of
	      neglecting refactoring and the improvement in quality characteristics.
	      The issue of measurement puts a dent into the shared vocabulary
	      between development and stakeholders as mentioned by a number of
	      software practioners from industry case studies (TODO: add industry
	      case study citation here).
	\item \textit{Fixed time period}. Financial debt arrangements have a fixed
	      \textit{maturity date}, where the debt must be paid back. On the other
	      hand, software quality issues do not a have a time limit and may be
	      kept in the product until they are resolved. Fixing these items relate
	      to paying back the "loan" taken on their creation. Such issues may
	      never be paid back if not needed to, resulting in an increased
	      cost-value ratio.
	\item \textit{Fixed interest}. A loan arrangement additionally consists of
	      fixed interest payments measured as a percetange of the loan value,
	      paid on an annual or bi-annual basis. The interest compensates for
	      the risk taken by the lender and encourages the loanee to pay back
	      quickly as possible in order to avoid paying back too much interest.
	      In reality, there is no such thing as fixed interest dependant on a
	      single factor in technical debt. Interest is difficult to quantify
	      as a matter of principal, and the amount of interest paid after a
	      period of time depends on future work.
\end{itemize}
Under these circumstances, what is considered "good structure" or "clean code"
is also heavily influenced to future development since future decisions
influence cost impact. As a consequence, no system is \textit{debt free} and
thus fixing every code violation would be an act of gold plating
\cite{Kruchten2012}. Additionally, what is the value of paying back this debt if
the product is competitive and the customers are happy \cite{Lim2012}?

% martin fowler - td quadrants
Fowler \cite{TDMartin} described this type of future debt as
\textbf{inadverted-prudent} debt. A project that was "clean" may find that after
a period of time that the initial approach taken might not have been the best.
He considered that developers learn on the job to perfect their craft as time
passes. The four quadrants refer to the types of technical debt that one might
encounter in a software project given the approach taken by the development
team. It was one of the four quandrants he defined, as shown in Figure
\ref{fig:td-quandrants}.

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{visualisations/TD_quadrants.png}
	\caption{Martin Fowler's Technical Debt Quadrants}
	\label{fig:td-quandrants}
\end{figure}


% unhedged call option
An alternative metaphor of technical debt \cite{UnhedgedCallOption}, described
bad code using finance terms in a similar fashion, but through a different
financial intrument called a call option. "\textit{An option is a financial
derivative that represents a contract sold by one party (the option writer) to
another party (the option holder). The contract offers the buyer the right, but
not the obligation, to buy (call) or sell (put) a security or other financial
asset at an agreed-upon price (the strike price) during a certain period of time
or on a specific date (exercise date).}" \cite{option-investopedia}. A call
option gives the right to buy while a put option gives the option holder the
right to sell. In software engineering, if a feature is hacked up quickly and
never touched again, then the project has reaped the rewards. The option "was
not called". However, if a new feature were required that would be influenced by
the quick and dirty work implemented earlier, then the requirement would be more
expensive to fulfill. In this case, the option "has been called" though it is
unclear whether interest was incurred during this time.


% conclusion
Defining software quality issues as a financial metaphor helps bridge vocabulary
shortcomings between developers and stakeholders. It helps management understand
current software development risks and encourages ways for managing these risks
as they are created. As Cunningham \cite{Cunningham1993} had written, technical
debt may be used as a strategy in order to meet business expectations however,
if not repaid promptly it could bring entire corporations to a standstill.

% types of TD
Initially, technical debt has solely focused on the internal quality issues of
systems developed. Such issues could be code smells, code violations and
duplicate or complex code. However, multiple types of debt have been
"discovered" spanning the entire software development environment.


A mapping study, conducted by Li et al. \cite{Li2015}, have analysed 94 studies,
overall dating 1992-2013, and have found 10 types of technical debt being
studied: requirements, architecture, design, code, test, build, documentation,
infrastructure, versioning and defect. The most prominent type of debt studied
was code debt, followed by test, architectural, design and documentation debt.

% architecture debt is the worst - industrial case study
However, in an industrial case study \cite{Codabux2013}, developers considered that
architectural debt is the most difficult to address, due to complexity and change
impact on project. Major architectural decisions are not taken in a vaccuum and
thus requires group meetings with other developers, software architects and
product managers. The time to reach a consensus on how to approach such changes
improve the cost of managing architectural debt.

% technical debt is "technical"
A few of the authors have considered that the metaphor of technical debt should
only apply to the low-level, internal quality characteristics such as code,
design, test, architectural debt rather than process gaps such as inadequate
quality assurance \cite{Theodoropoulos2011} \cite{Nugroho2011}. Thus the word
"technical". However, business process gaps may negatively affect projects and
incurr technical debt as a result.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Identification and Measurement}

% What are the causes of code TD?

Technical debt may impede future development and delivery of new features if not
managed appropriately \cite{Cunningham1993}. Cunningham's statement was
validated by a number of authors by looking at the most "notorious" code smells
\cite{Fowler1999} and their impact on software projects.

Olbrich et al. \cite{Olbrich2009} studied the impact of two code smells, God
class and Shotgun Surgery, on change proneness of class entities and size of
changes within two open source systems, namely Apache Lucene and Apache Xerces.
They gathered data on the number of smells in the systems over revisions and the
distribution of changes on classes suffering from these two smells. The authors
concluded that large systems are more prone to increase the number of code
smells as it evolves over time and particularly, that classes suffering from the
God class smell are 4 to 5 times more change prone than other non-smelly
classes. However, this might be due to the large amount of functionality of the
class suffering from the smell. Additionally, the study was conducted only on
open-source systems and the results might not be applicable to commercial
software. Additionally, due to limitations of the tool used to identify code
violations, only public Java classes have been analysed.

In a similar study, Fontana et al. \cite{Fontana2012} studied the impact of
removing code smells on code quality metrics. The authors looked at three common
smells: Data class, God class and Duplicated Code. Additional goals were to find
out which code smell incurs the most TD and whether their impact is related to
the domain of product being built. The metrics impacted are cohesion, coupling
and complexity. Proper refactoring practices were applied for each smell whilst
the quality metrics were re-evaluated to assess their impact. The results showed
that refactoring of one code smell may provide benefits for one or more metric
qualities but may negatively impact others. Interestingly, they had found that
the Data Class smell and God class smells frequency may be domain-dependent.

An exploratory study by Khomh et al. \cite{Khomh2009} empirically analysed the
impact of 29 code smells on the change sets of 9 releases of two open source
systems. They had confirmed the results of the previous studies that code smells
increase the number of changes that software undergoes during its evolution.
Additionally, they had found that classes containing more than one code smell
are more change prone than other classes. Moreover, they found a possible cycle
of repairing smells and better to have new ones between releases.

An interesting idea from all authors \cite{Olbrich2009}, \cite{Fontana2012} and
\cite{Khomh2009} stated that not all code smells have the same consequences on
the code base. A code smell may have been deliberately introduced due to the
nature of project domain. For example, in the case of a system that uses
computer vision algorithm and techniques might be prone to an increased
cyclomatic complexity and God class smells.

% prioritisation by severity - interest probability
Thus, Charalampidou et al. \cite{Charalampidou2017} introduced a study that
assessed the interest probability of code smells, where the interest probability
is the probability of a code smell to introduce extra changes in future
development. Interest probability was calculated by counting the frequency of
each code smell and how it correlates with the change proneness of the module
where it resides. The smells studied were Long Method, Conditional Complexity,
and Duplicated Code. The results showed that code duplication has the highest
interest probability due to the number of changes required to maintain future
development. Additionally, high cyclomatic method complexity increases amount of
changes.

% prioritisation on context
Additionally, prioritising code smells with the highest severity might not be
suitable if the context in which the smell resides will not be referenced in the
future. Therefore, Sae-Lim et al. \cite{Sae-Lim2016} looked at prioritising code
smells according to development context to support a \textit{prefactoring}
stage, where developers clean up code before development of new features. The
authors calculated a value for each code smell, called the \textit{Context
	Relevance Index}, based on a list of issues from the project's issue tracker and
the change descriptors of commits in the project version control. The results of
their preliminary study returned a list of ranked code smells to be targetted as
a prefactoring step to implementation. This type of prioritisation may be more
practical in time constrained projects.

% conclusion of measurement TODO: add citation here 
Code smells are technical debt items and increase future development and
maintainance costs. Industry case studies have shown that TD items are more
likely to be addressed if made visible by developers within the project's issue
tracker. However, from the perspective of a project manager, it is of importance
to know how much effort the team will put into technical debt reduction and
whether there is an associated business value with this investment. Hence,
subsequently to the identification stage of code smells, there must exist a
measurement stage of the amount of work effort technical debt will introduce to
be resolved and the consequences on productivity over time if the team keeps
hold of the code violations.

% How to quantify code smell impact?

% introduction
Identification and prioritisation are two of the most important stages when
dealing with technical debt. Making technical debt items such as code smells
visible has been recommended by industry practitioners \cite{Lim2012}
\cite{Codabux2013}. However, participants have struggled to find a way to
measure technical debt and its cumulative effect over time. This is a
particularly important aspect of project managers responsibility when planning
new work for the team. Whilst developers are concerned with the health and
quality of the codebase, managers are responsible with balancing work by keeping
developers and stakeholders happy.

Specifically, a technical debt item raises two important questions:
\begin{itemize}
	\item How much effort does it take to repair it?
	\item What are the consequences of holding on to it?
\end{itemize}

Answering these two questions through a quantified measure is the key to a
proactive management of technical debt. The measure depicting the cost of paying
back the debt at the present time is called the \textit{principal} whilst the
extra cost of development when keeping hold of items is called
\textit{interest}. Unfortunately, there is no standardised method, due to
difficulties managing complexities of quantifying work effort and development
costs. However, a number of studies have appeared over the years that look at
methods for calculating principal and interest of technical debt items.

Bohnet et al. \cite{Bohnet2011} proposed a tool to bridge the gap between
development teams and corporate managers, by exposing internal system quality
through the use of \textit{software maps}. A software map is a hierarchical
2D/3D view of software artefacts, each represented visually through properties
such as colour, texture and size; each representing a property of quality:
cyclomatic complexity, lines of code and nesting levels. Such a visualisation
provides both developers and managers with points of fragility where possible
bugs may arise and highlights areas of work to address. However, the
visualisation is technical and might be difficult to convey to stakeholders.
Additionally, there is no way to calculate the principal and interest of the
quality issues.

% sqale method for measuring technical debt
Letouzey et al. \cite{Letouzey2012} proposed a different method, called the SQALE
method. The goal was to create a standardised, language-agnostic framework for
assessing the quality of source code by deriving measures for code
characteristics and calculating an overall measure of technical debt. The
framework proposed consisted of four concepts:
\begin{itemize}
	\item Quality Model - defines internal properties of code through a
	      structured three-layer hierarchy (characteristic, sub-characteristic and
	      requirement). For example, a characteristic is maintainability,
	      sub-characteristic is readability and the requirement is no commented
	      code. The hierarchy is defined as all requirements could be converted into
	      actionable steps. Each requirement defines a remediation index (cost to
	      repair code violations) defined in time, work or capital units.
	\item Analysis Model - measurement of the distance between the current
	      state of the application and the \"optimized\" quality target.
	\item Indices - these are the values that represent the costs of paying
	      back debt.
	\item Indicators - provide a visual representation of technical debt indices
	      through ratings.
\end{itemize}
The indices were calculated by summing up the principal of each code violation
and aggregating up into the sub-characteristics and further to the
characteristics of the Quality Model. The technical debt index is provided
through the aggregation of all the characteristics in the Quality Model.
Although the framework provides a good measurement of technical debt from the
principal of code violations, there is no calculation of interest if TD items
are not reduced and, additionally, it does not take into consideration
architectural debt issues. Subsequently to their study, the method was
implemented in SonarQube, which is a continuous code quality tool.

Curtis et al. \cite{Curtis2012} summarized the results of a language agnostic
study on a huge database (365M lines of code) of software projects across 10
industries which provided a formula for estimating the principal of TD items.
The authors used CAST's Application Intelligence platform to statically analyse
source code, using 1200 rules of coding "best practices". They identified code
violations by analysing source code and aggregated the results into quality
characteristics, or \textit{health factors}. Scores from each health factor were
aggregated on a scale of 1 (high risk) to 4 (low risk). The total principal was
estimated by a formula with three parameters: number of problems, time required
for each fix and the cost of fixing the issue. Unfortunately, the methodology
did not support calculation of holding on to code issues. The authors concluded
that estimating the interest incurred by a TD item was difficult since multiple
hidden factors influence the results. The term works well with the phenomenon
since stakeholders think of software quality in terms of business.


Nugroho et al. \cite{Nugroho2011} looked at defining an empirical formula for
quantifying principal and interest. The authors had completed an empirical
analysis of 44 projects within the Software Improvement Group (SIG) using TUViT
software quality assessment method for collecting relevant metrics: lines of
code, code duplications, etc. The had defined technical debt from an opposite
perspective, as the changes needed to bring a system from its current quality
state to the "ideal" quality. They considered technical debt to be equivalent to
a measurement of repair effort (RE). Calculation of this measure required the
number of lines of code that need to changed, the estimate work effort of
rebuilding the feature from scratch and a margin of error. The interest was also
derived from the extra cost spent on maintainance monthly and yearly, modelled
against the current state of quality. The conclusions were that the formulas for
principal and interest could be used in quantifying important business
information such as Return on Investment (ROI). However, due to the nature of
ranking system quality (scale of 1-5), it would be a challenge to get ROI right.


Another study was conducted by Singh et al. \cite{Singh2014}, where technical
debt interest payments were calculated by monitoring of development effort and
code comprehension. The proposed approach monitors time spent by developers in
classes with known TD items, detected initially by static analysis tools. They
integrated a tool within the Integrated Development Environment of developers
and gathered information of class visits, development session times within the
class. The interest was calculated as the difference between time practically
spent in classes and the ideal time spent. The results showed that developers
tend to spend more time in classes containing TD items than others. However, the
study was conducted with the input of one developer over a period of 9 months.
Additionally, estimating the ideal time spent on development is a challenging
task due to multiple personal factors such as level of project knowledge,
familiarity of environment and programming language, etc. A possible solution
would be to study development time from a more coarse-grained approach, from a
feature or release level.

Gomes et al. \cite{Gomes2011} studied the correlation between software
evolution, defect occurrence and work effort deviation at the release level. The
authors extracted data from multiple documentation sources such as test plans,
project plan, weekly reports, project source code, and emails. Using this data,
they could derive important team information on change, effort, quality, test
and size of the system. They measured extra work effort by subtracting the
estimated work time and total work time. Although information at the release
level offers project managers an idea of work effort deviation, it does not show
at a granular level what defects slow down development of a new feature and
where the team should focus their refactoring activities.

% Tools?

These types of measurements are useful for project managers when making
decisions as to what percentage of work on an interation to be assigned on
refactoring. To keep up with a constantly changing system, there are software
quality tools used in industry that analyse source changes, highlight possible
fixes and some have automatic refactoring features.

% experience report on code smell detection tools
Fontana et al. \cite{Fontana2011} compiled an initial report on code smell
detection tools and their experience on the analysis of multiple versions of an
object-oriented Java project. The goal of their study was to contrast the
performance of these tools in relation with known code smells in the source
code. These tools were: Jdeodorant, PMD, iPlasma, InFusion, StenchBlossom. There
were numerous code smells initially detected in the project including God Class,
Data Class, Feature Envy, Brain Method, etc. Their methodology was to apply
analysis on multiple versions of an object-oriented project, with all code
smells known beforehand. They have found not all tools identify all the code
smells in the project and some had different names for the same code smell.
Additionally, some tools shared the same metrics and identified the same
collection of smells, whereas others had widely different results.

% Technical Debt Indexes Provided by Tools
Unfortunately, the experimented tools had only the ability to identify code
violations and link them to the source code. No tool had features on quantifying
software quality and no mention of a global technical debt measurement. Other
tools have been implemented which provide such aggregated values. They provide
the ability to calculate the "quantity" of technical debt as well as a total
estimated amount of effort for its reduction. However, each tool takes into
consideration different information sources and calculates the overall TD
measurement in a different way since there exists no standard method on
aggregating such a complex phenomenon into a single value.

Hence, a new study by Fontana et al. \cite{Fontana2016}, had looked into the 5
code quality tools that provide these features, with the goal to understand how
they calculate technical debt, what sources of information they take into
account and what features they are missing. The study looked at the following
tools:
\begin{itemize}
	%TODO: add link to pages
	\item \textbf{CAST}. Defines technical debt cost by taking both principal
	      and interest into consideration. The principal is calculated by the
	      severity, time and cost to fix structural flaws. Interest is then computed
	      by assuming that a business will resolve a fixed percentage of high, medium
	      and low severity items, times the cost of labour set at 75\$ per hour.
	\item \textbf{InFusion}. Calculates a measurement, Quality Deficit Index,
	      which summarizes the level of quality of a system. It takes into account all
	      design flaws of a source code, each described by negative influence on best
	      practices, level of granularity (method or class level) and smell severity.
	\item \textbf{Sonargraph}. The distinction from the rest of the tools is
	      that developers can set a defined initial architecture and Sonargraph can
	      find deviations from that architecture at the level of system, project and
	      build. Additionally, the tool generates two Structural Debt measurements, an
	      index related to the sum of all dependencies needed to be cut and a cost
	      measurement calculated from the index multiplied by a time factor.
	\item \textbf{SonarQube}. A continous code quality tool that uses a large
	      amount of rules for good coding practices to find code violations. The
	      resulting code violations are aggregated into software quality characterstic
	      factors which then compute a Technical Debt Index. The index is expressed in
	      the of work effort required to fix all issues. Rules and costs may be
	      modified to support customised business requirements (available in the
	      commercial version). It implements the SQALE method of measuring technical
	      debt \cite{Letouzey2012}.
	\item \textbf{Structure101}. Tool specialised in architectural issues of the
	      codebase, with metrics on multiple levels of granularity such as method,
	      class, package and project level.
\end{itemize}

The authors have provided summarized tables that describe all the tools and
their purpose nicely. The two tables are available in Figure \ref{fig:tools-tables}.

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{visualisations/tools-table.png}
	\caption{Summary of tools provided by Fontana et al.}
	\label{fig:tools-tables}
\end{figure}

Unfortunately, there is no standard method of measuring the total technical of a
system. This is due to the complex nature of the metaphor and one cannot capture
all its complexities into a single tool. Therefore, there is no single best tool
for this purpose, as all take into consideration different sources for metric
computation and it all comes down to the requirements of the team looking to
increase the level of software quality.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Management}

Although tools provide managers with an approximate measure of quality of the
code base, there is a danger in associating technical debt with the results of
software quality tools. As mentioned in Section \ref{section:def}, there
are numerous types of technical debt that may have a negative impact on the ROI
of the business. For example, code quality tools cannot predict that the
requirements gathering phase was not completed appropriately or that build debt
is affecting infrastructure costs \cite{Morgenthaler2012}.

Additionally, a study by Martini et al. \cite{Martini2017} showed that the
overall impact of technical debt at the project level is not same as the sum of
all technical debt items. They assessed four projects and interviewed both
project managers and developers on their perspective of the impact, on a scale
from 1 to 10. Although the interviewees had multiple backgrounds and were
consulted on many development factors (reduced development speed, bugs incurred
by TD, extra costs, frequency of issues, spread in system, users affected,
etc.), the results showed that there are other complexities affecting the
project.

Technical debt should be used as a strategy for quick development of features in
order to satisfy an immediate business requirement such as TTM. From an
industrial case study \cite{Lim2012}, a developer described TD as follows:
"\textit{Technical debt is a balance between software quality and business
	reality}". Industry practitioners from the same study have acknowledged that
numerous business requirements have forced them to incur debt. Unfortunately,
business requirements and decisions are difficult to foresee due to constant
market deviations, such as the appearance of a new competitor or a new
technology.

Therefore, technical debt is difficult to predict. However, it is recommended
that once debt is incurred, it should be made visible \cite{Lim2012}
\cite{Codabux2013} \cite{Morgenthaler2012}, and paid back as early as possible.
Cunningham \cite{Cunningham1993} describes it best: "\textit{The danger occurs
	when the debt is not repaid. Every minute spent on not-quite-right code counts
	as interest on that debt. Entire engineering organizations can be brought to a
	stand-still under the debt load of an unconsolidated implementation,
	object-oriented or otherwise.}".

Fortunately, project management methodologies such as Agile and its associated
practices have proved to help reduce and manage technical debt
\cite{Holvitie2014} \cite{Trumler2016}. In particular, Test Driven Development (TDD),
following coding standards, refactoring, continuous integration, collective code
ownership and pair programming have been considered to help tackle technical
debt.

From a project manager's perspective, technical debt must be managed at cost
level by iteration. How many resources should the team invest in technical debt
reduction over the next sprint? What issues should the team tackle first and
what will the benefits be?

Guo et al. \cite{Guo2011} suggested that technical debt should be managed
similar to a financial portfolio perspective by encouraging each item to be
viewed as an investment. Debt items would take on the role of assets, with the
same goals: maximize return and minimize risk. The decision framework would be
based on historical metrics of all TD items to decide which ones to keep and
which ones to pay back. However, the approach is difficult to achieve in
practice due to limitations of the metaphor \cite{Schmid2013}.

Seaman et al. \cite{Seaman2012} proposed four ways to aid in this decision
making:
\begin{itemize}
	\item Cost-Benefit Analysis. The technique is based on principal, interest
	      probability (the probability that other work will be more expensive),
	      interest amount and their associated value (high, medium, low). Using these
	      it would be possible to estimate items that have low principal (are quick to
	      repay) and a possible high impact on future additions and changes.
	\item Analytic Hierarchy Process (AHP). Technical debt items are ranked
	      according to a defined criteria, based on the needs and requirements of the
	      team. A ranked list of items to work on is created through meetings and
	      group decisions.
	\item Portfolio Approach. Guo et al. \cite{Guo2011} has
	      defined an approach for portfolio debt management. The same approach has
	      been defined here.
	\item Options. This technique considers that each repayment of debt is an
	      investment in the future. It is similar to a purchase of an option
	      \cite{option-investopedia} that will be called in the future.
\end{itemize}

Power \cite{Power2013} illustrated the impact of technical debt on Agile teams
and methods of management using options, from Cisco System's Agile Office
data-set. He proposed that The items of the portfolio are the slices of time the
team invests in a particular activity. For example, a team may allocate 50\% of
their time to development of new features, 20\% to testing, 15\% to fixing
defects and 5\% resolving technical debt items. An example could be viewed in
Figure \ref{fig:td-options}.

\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{visualisations/td-options.png}
	\caption{A partitioning example of work effort, provided by Cisco System's Agile Office}
	\label{fig:td-options}
\end{figure}

Similar to previous stages of technical debt, management is no easy feat.
Project managers must balance the work effort, costs with benefits, future
technical impact and return on investment. This can only be possible if
technical debt is visibile during software evolution \cite{Lim2012}
\cite{Morgenthaler2012} \cite{Codabux2013}, is continously tracked and managed
appropriately \cite{Cunningham1993}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Conclusion}

Technical debt is a difficult phenomenon to tackle in software engineering.
Development teams face challenges in identifying, tracking, managing and
explaining the concept to non-technical stakeholders. However, new tools allow
the indentification of code smells, tracking and computing of complex indexes
with focus on quality characteristics of code. Project management practices
allow for appropriate allocation of resources to refactoring activities.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Approach}
\label{proposed-work}

As mentioned, in the introduction, this study is focused on finding the relation
between technical debt and work effort. This will yeild more information for
developers on time management, for project managers on debt investment and for
stakeholders on understanding a technical concept in terms of labour cost.

The approach for this study will consist of the following steps:
\begin{enumerate}
	\item \textit{Identify appropriate data candidates for this study}.\\
	      These are potential software projects that are suitable for study. At best,
	      they should have multiple developers contributing to the project, a medium
	      to large codebase with a variety of historical data and an associated issue
	      tracking software. Ideally, the team would have integrated a continous code
	      quality tool for tracking code smells throughout software evolution. This
	      would help with quick and automatic identification of present and historical
	      code issues.

	      The study would also benefit from a mixture of open-source and
	      commercial sofware to contrast the differences between the two environments
	      and, possibly, arrive at general conclusions that may apply to both worlds.

	\item \textit{Identify suitable work items from issue tracker}.\\
	      In this step, the purpose is to understand important events in the evolution
	      of the data candidates. Ideally, events were tracked in the form of tickets
	      with detailed information attached, such as:
	      \begin{itemize}
		      \item Priority. This field will give a sense of importance to the
		      work item. It will be interesting to find development patterns
		      based on this field. Will developers take more time to design and
		      implement an important work item? Or are they pressured to deliver
		      and thus introduce more debt in the system?
		      \item Estimated Work Effort. This is one of the most important
		      fields for calculation of extra work effort. This provides the
		      theoretical work time on which to compare the practical work time
		      measured in this experiment.
		      \item Timestamps. The opening and closing timestamps of a ticket
		      may offer valuable information for measuring the practical work
		      effort (in hours).
	      \end{itemize}

	      This type of information would give an idea of the type of work involved.
	      Unfortunately this data is not always available. The most important is the
	      estimated work field as without it, the extra work cannot be identified. If
	      this field does not exist in the ticket, the work item will not be included
	      in the study.

	\item \textit{Identify version control checkpoints}.\\
	      Successfully completed work items can be tracked in the version control
	      repository of the project. Identifying checkpoints will aid in understanding
	      the amount of effort put into the work item by the team and how it diverges
	      from the initial estimation.

	      Ideally, the team should have links between revisions of the codebase and
	      the work item in the issue tracker. This would make it easier to find the
	      associated checkpoints.

	\item \textit{Measure the amount of work effort for each work item}.\\
	      The purpose is to understand how many practical changes a work item has
	      induced over its lifetime. This could be done in two ways: at the code and
	      issue tracker levels.

	      At the code level, it is possible to understand the level of work effort
	      involved by aggregating the number of changes a work item has suffered. A
	      change set consists of the number of lines of code added, deleted and
	      modified. Granularity can be at the pull request, commit, class and method
	      level. Version control systems such as Git provide features of retrieving
	      change sets between revisions.

	      However, identifying work effort from change sets is a challenging task. It
	      is difficult to quantify in man-hours since many changes may be generated
	      automatically by modern refactoring tools in the integrated development
	      environment. An alternative solution is to compare the timestamps between
	      the first and the last commit. The temporal difference might provide a
	      practical estimate of work effort to resolve the issue. Unfortunately, this
	      case only works when a developer works on a single issue at a time.

	      At the ticket level, one can understand the amount of work effort realised
	      by a team member. In an ideal case, the team enforces developers to log
	      their time spent designing and implementing a feature. However, that is not
	      always the case. An alternative option, would be to retrieve the timestamp
	      of ticket events, such as the opening and closing of an issue.
	      Unfortunately, this might not give an approximate time of work since:
	      \begin{itemize}
		      \item The team does not respect the opening and closing of a ticket time
		            according to their development patterns. For example, a developer might
		            start work on an issue before marking it as "In Progress". This will
		            introduce a margin of error in the estimation process.
		      \item Tickets might remain open for a long period of time, whilst the
		            feature was implemented in a relatively short time. Therefore this
		            option would give an incorrect estimate of the amount of work completed.
		      \item There are differences between commercial and open-source software.
		            For example, developers might work in the timeframe of 9AM to 6PM in
		            commercial environment whilst in open-source they are free to work at
		            any time of the day. For example, in the extreme case, a developer marks
		            a ticket as "In Progress" before end of working day, and resume the work
		            the following morning. In this case, our estimation of approximately 15
		            hours of development time for this work item would be incorrect.
	      \end{itemize}

	      For this study, the code level technique will be implemented. The work
	      effort from issue tracking will be implemented in a parallel study.
	      However, it would be interesting to gather results from both methods
	      and see how they correlate. Additionally, the two result sets may
	      complement one another and provide an overall effort metric. However,
	      as discussed, there are many complexities and cases that will need to
	      be managed to get the real estimate.

	\item \textit{Measure technical debt items}.\\
	      The scope of this step is to identify code violations within change
	      sets. For each work item implemented there will be a set of associated
	      modules, classes and methods affected.

	      These will be the search areas for code smells. Using a continous code
	      quality tool, historical code smells can be tracked against the evolution of
	      software. If enough data is available, then patterns surrounding feature
	      implementation and bug fixing can be identified.

	      Ideally, the team would have the code quality tool integrated into
	      their continous integration environment. If so, then historical code
	      smell data could be leveraged by retrieving it through an API.
	      However, that is not always the case. Therefore, a code quality tool
	      must be used to analyse the version control checkpoints identified and
	      find code smells that may have an impact on change sets of a feature.

	\item \textit{Analysis and discussion of results}.\\
	      Once all previous steps have been fulfilled, the three data sources
	      can be linked together. Extra work can be correlated to issue tracking
	      information and code quality. Technical debt could be classified by
	      the type, priority and asignee of ticket as well as code smells and
	      other code violations.
\end{enumerate}

Unfortunately, the proposed work is not as straightforward. There are many
complexities of the work environment which cannot be taken into consideration
from the three data sources. Therefore, we will make some assumptions:
\begin{itemize}
	\item The team uses Git for version control and follows the pull request model
	      for implementing changes.
	\item Only one developer is assigned to an issue.
	\item A developer works on maximum one issue at a time.
	\item The team uses an issue tracker consistently. Developers change the
	      status of the ticket according to their current development progress. For
	      example, if a team member got started on a work item, she would set the the
	      ticket status to "In Progress". Respectively, she would mark the ticket as
	      "Closed" if development ceased, her changes were reviewed and integrated
	      into the main branch.
	\item The team estimates the theoretical amount of work necessary to
	      implement a feature or fix a bug. This measure is attached to each
	      work item selected.
	\item Development time is between 9AM to 6PM UTC. Only work items with
	      opening and closing status between these two values are taken into
	      consideration. For example, if a developer starts work on a feature on
	      Monday 5PM and finishes it by Tuesday 1PM, then development time will be
	      considered to be 4 hours (1 hour Monday, 3 hours Tuesday). This assumption
	      will simplify the calculation of practical work hours for work items.
\end{itemize}

These assumptions will reduce the amount of real world complexity in the
experiment and allow for simple validation of the results. Additionally, the
complexities may be explored in future studies.


\subsection{Limitations}

As dicussed in Section \ref{section:def} there are multiple types of debt
affecting the software environment which cannot be modelled in this study.
Additionally, with the introduction of assumptions in order to limit the
complexity of the study there are many threaths to the validity of the results.

\begin{itemize}
	\item Data candidates may not have sufficient information related to the
	      estimation of work effort. We believe this statement is especially true for
	      open-source software, with an international team and contributions from many
	      other developers. Although care will be taken in the selection process,
	      there is no assurance that this data will be provided. However, if
	      commercial projects do have estimation fields, it would be interesting to
	      correlate the amount of practical work done between the two worlds for
	      similar tickets.
	\item Work effort measurement is a difficult challenge, and was deemed
	      unmeasureable by Martin Fowler \cite{CannotMeasureProductivity}. Restricting
	      development time to an interval and discarding multi-developer work items
	      may reduce the data set considerably.
	\item Code quality tools may not detect potential technical debt items. For
	      example, architectural debt is an important factor in assessing extra work but
	      this type of debt which was not included due to its complexity.
	\item The assumptions made in the previous section may not reflect the real
	      work environment. Developers may be working over time if, for example, under
	      the pressure of a release schedule.
	\item There are many types and complexities of technical debt which were not
	      included. Requirements, architectural, build, infrastructure, etc. all have
	      an influence on the amount of effort for finalising a feature.
\end{itemize}

Although there are risks associated with measurements, care will be taken to
consider all possibilities when validating calculation of measurements. This is
especially true in the case of quantifying work effort.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Work Plan}
\label{work-plan}

Considering the proposed work in Section \ref{proposed-work}, work packages can
be easily created by indentifying activities. These activities could be placed
in time slots, spanning 11 weeks worth of experimental work from January 2018
until April 2018. The work packages and activities are as follows:

\begin{enumerate}
	\item \textit{Gathering data}.\\
	Activities included:
	\begin{itemize}
		\item Identify commercial and open-source software project suitable for
		the purpose of this study.
		\item Familiariasing with development environment of commercial software
		and limitations of the work involved.
		\item Select code quality tools that support the programming language of
		the software.
		\item Identify important work items relevant for the study. This may
		include items such as features, bugs, enhacements, etc.
	\end{itemize}

	Estimated work time: 3 weeks.\\
	
	\item \textit{Development of automated tools}.\\
	Activities included:
	\begin{itemize}
		\item Design and development of a tool for retrieving ticket information
		from the project issue tracker.
		\item Design and development of a tool for changing between revisions of
		the source code and measuring effort by change sets and storing
		timestamps between revisions.
	\end{itemize}

	Estimated work time: 3 weeks.\\

	\item \textit{Measuring technical debt}.\\
	Activities included:
	\begin{itemize}
		\item Usage of code quality tool on revisions to identify code smells
		within change sets.
		\item Integration of the code quality tool features with the previous
		tool for measuring revisions.
	\end{itemize}

	Estimated work time: 2 weeks.\\

	\item \textit{Data Verification and Analysis}.\\
	\begin{itemize}
		\item Analyse data integrity for inconsistencies and remove outliers.
		\item Statistically test the correlation between work effort and technical debt.
	\end{itemize}

	Estimated work time: 3 weeks.\\

	\item \textit{Presentation of results and report writing}.
	Estimated work time: 3 weeks.\\

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

To conclude, technical debt is a phenomenon difficult to measure accurately and
assess potential development and business costs. Therefore, understanding it
from the perspective of developers is vital as they are first-hand involved in
the implementation of new features. Any extra work spent as a result of previous
incurred debt increases business costs. If too much debt accrues over the
lifetime of a project, the entire project may be brought to a standstill.

As a result, this study will try to understand technical debt from a development
work effort perspective. It will, possibly, shed light on the types of features
that take a lot of man-hours to complete in correlation with the level of
technical debt at the present time of the implementation. 

Through measurement and analysis of these two metrics and their relationship,
developers may discover bottlenecks in productivity, managers may allocate
appropriate resources for refactoring activities and business stakeholders may
become more aware of development concerns. Additionally, it will be interesting
to find the discrepancy between open-source and proprietary software projects.

To the best of my knowledge, this type of study had not been conducted before
from the perspective of work effort at the feature level granularity and may
provide valuable insights into the development patterns of software engineering.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% it is fine to change the bibliography style if you want
\pagebreak
\bibliographystyle{plain}
\bibliography{mprop}
\end{document}
